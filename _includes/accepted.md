1. Constructing Memory: Consolidation as Teacher-Student Training of a Generative Model. Eleanor Spens, Neil Burgess. [Video](https://youtu.be/F1KVuWgTF0E).
2. Biological Neurons vs Deep Reinforcement Learning: Sample efficiency in a simulated game-world. Forough Habibollahi, Moein Khajehnejad, Amitesh Gaurav, Brett J. Kagan. [Video](https://youtu.be/_QloC8gVqDA).
3. Leveraging Episodic Memory to Improve World Models for Reinforcement Learning. Julian Coda-Forno, Changmin Yu, Qinghai Guo, Zafeirios Fountas, Neil Burgess. [Video](https://youtu.be/Vd3SqFjLcT4).
4. Differentiable Neural Computers with Memory Demon. Ari Azarafrooz. [Video](https://youtu.be/TplyJMKrMr4).
5. A Universal Abstraction for Hierarchical Hopfield Networks. Benjamin Hoover, Duen Horng Chau, Hendrik Strobelt, Dmitry Krotov. [Video](https://www.youtube.com/watch?v=x_jJed5KjP8).
6. Interpolating Compressed Parameter Subspaces. Siddhartha Datta, Nigel Shadbolt. [Video](https://www.youtube.com/watch?v=J8L69slXjl4).
7. Associative memory via covariance-learning predictive coding networks. Mufeng Tang, Tommaso Salvatori, Yuhang Song, Beren Gray Millidge, Thomas Lukasiewicz, Rafal Bogacz. [Video](https://youtu.be/Trn_1Q6qZdE).
8. Self-recovery of memory via generative replay. Zhenglong Zhou, Geshi Yeung, Anna C. Schapiro. [Video](https://www.youtube.com/watch?v=vx1raAyDgMY).
9. The Emergence of Abstract and Episodic Neurons in Episodic Meta-RL. Badr AlKhamissi, Muhammad ElNokrashy, Michael Spranger. [Video](unavailable).
10. Multiple Modes for Continual Learning. Siddhartha Datta, Nigel Shadbolt. [Video](https://www.youtube.com/watch?v=rtH2EZeNcaw).
11. The Opportunistic PFC: Downstream Modulation of a Hippocampus-inspired Network is Optimal for Contextual Memory Recall. Hugo Chateau-Laurent, Frederic Alexandre. [Video](unavailable).
12. Recall-gated plasticity as a principle of systems memory consolidation. Jack Lindsey, Ashok Litwin-Kumar. [Video](unavailable).
13. Learning to Reason and Memorize with Self-Questioning. Jack Lanchantin, Shubham Toshniwal, Jason E Weston, Arthur Szlam, Sainbayar Sukhbaatar. [Video](https://recorder-v3.slideslive.com/#/share?share=78356&s=b216b880-3496-464c-a5d4-0cda4830c677).
14. Informing generative replay for continual learning with long-term memory formation in the fruit fly. Brian S Robinson, Justin Joyce, Raphael Norman-Tenazas, Gautam K Vallabha, Erik Christopher Johnson. [Video](https://youtu.be/grJxdWNi10k).
15. Characterizing Verbatim Short-Term Memory in Neural Language Models. Kristijan Armeni, Christopher Honey, Tal Linzen. [Video](https://youtu.be/MWhsm4rMSxc).
16. Memory in humans and deep language models: Linking hypotheses for model augmentation. Omri Raccah, Phoebe Chen, Theodore L. Willke, David Poeppel, Vy A. Vo. [Video](https://vimeo.com/manage/videos/771770003/privacy).
17. Transformers generalize differently from information stored in context vs in weights. Stephanie C.Y. Chan, Ishita Dasgupta, Junkyung Kim, Dharshan Kumaran, Andrew Kyle Lampinen, Felix Hill. [Video](https://www.youtube.com/watch?v=Cqdyobq18Tk).
18. Mixed-Memory RNNs for Learning Long-term Dependencies in Irregularly-sampled Time Series. Mathias Lechner, Ramin Hasani. [Video](https://youtu.be/E8hHioZM5-M).
19. Neural Network Online Training with Sensitivity to Multiscale Temporal Structure. Matt Jones, Tyler R. Scott, Gamaleldin Fathy Elsayed, Mengye Ren, Katherine Hermann, David Mayo, Michael Curtis Mozer. [Video](https://drive.google.com/file/d/1rERjhNuvvBBPCSF8bpWvUGJdxQOhAmiz/view?usp=drive_web).
20. Learning at Multiple Timescales. Matt Jones. [Video](https://drive.google.com/file/d/1QDlePHw-TuE0wmVI9kbC_iO3CERr9WFk/view?usp=drive_web).
21. Toward Semantic History Compression for Reinforcement Learning. Fabian Paischer, Thomas Adler, Andreas Radler, Markus Hofmarcher, Sepp Hochreiter. [Video](https://youtu.be/TIgZT4_2oOg).
22. CL-LSG: Continual Learning via Learnable Sparse Growth. Li Yang, Sen Lin, Junshan Zhang, Deliang Fan. [Video](https://www.youtube.com/watch?v=i85GwHoU0aM).
23. Cache-memory gated graph neural networks. Guixiang Ma, Vy A. Vo, Nesreen Ahmed, Theodore L. Willke. [Video](unavailable).
24. Exploring The Precision of Real Intelligence Systems at Synapse Resolution. Mohammad Samavat, Thomas M Bartol, Kristen Harris, Terrence Sejnowski. [Video](unavailable).
25. Low Resource Retrieval Augmented Adaptive Neural Machine Translation. Harsha Lakkamaneni, Swair Shah, Anurag Beniwal, Narayanan Sadagopan. [Video](https://drive.google.com/file/d/1GymE6_RvNk5SVPc1aXMOuczGNaPThbC2/view).
26. Neural networks learn an environment's geometry in latent space by performing predictive coding on visual scenes. James Gornet, Matt Thomson. [Video](unavailable).
27. Transformer needs NMDA receptor nonlinearity for long-term memory. Dong-Kyum Kim, Jea Kwon, Meeyoung Cha, C. Justin Lee. [Video](https://youtu.be/PQA_HuXTfes).
28. Training language models for deeper understanding improves brain alignment. Khai Loong Aw, Mariya Toneva. [Video](https://youtu.be/rEVvJb1odoo).
29. Using Hippocampal Replay to Consolidate Experiences in Memory-Augmented Reinforcement Learning. Chong Min John Tan, Mehul Motani. [Video](https://www.youtube.com/watch?v=lm5ozEzoolE).
30. Evidence accumulation in deep RL agents powered by a cognitive model. James Mochizuki-Freeman, Sahaj Singh Maini, Zoran Tiganj. [Video](https://www.youtube.com/watch?v=RkbAsCRpsP0).
31. Meta-Learning General-Purpose Learning Algorithms with Transformers. Louis Kirsch, Luke Metz, James Harrison, Jascha Sohl-Dickstein. [Video](https://youtu.be/k02rygHSlrA).
32. Experiences from the MediaEval Predicting Media Memorability Task. Alba Garcia Seco de Herrera, Mihai Gabriel Constantin, Claire-Hélène Demarty, Camilo Luciano Fosco, Sebastian Halder, Graham Healy, Bogdan Ionescu, Ana Matran-Fernandez, Alan F. Smeaton, Mushfika Sultana. [Video](https://youtu.be/LQyWnpQho6o).
33. Constructing compressed number lines of latent variables using a cognitive model of memory and deep neural networks. Sahaj Singh Maini, James Mochizuki-Freeman, Chirag Shankar Indi, Brandon G Jacques, Per B Sederberg, Marc Howard, Zoran Tiganj. [Video](https://youtu.be/ZGJDHycWEBQ).
34. Learning to Control Rapidly Changing Synaptic Connections: An Alternative Type of Memory in Sequence Processing Artificial Neural Networks. Kazuki Irie, Jürgen Schmidhuber. [Video](https://drive.google.com/file/d/1fguRNEZ0VvN0o-Ozb1ucPofdC5p48eot/view?usp=sharing).
