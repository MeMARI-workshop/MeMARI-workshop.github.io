1. Constructing Memory: Consolidation as Teacher-Student Training of a Generative Model. Eleanor Spens, Neil Burgess. [Paper](papers/paper_1.pdf). [Video](https://youtu.be/F1KVuWgTF0E).
2. Biological Neurons vs Deep Reinforcement Learning: Sample efficiency in a simulated game-world. Forough Habibollahi, Moein Khajehnejad, Amitesh Gaurav, Brett Joseph Kagan. [Paper](papers/paper_2.pdf). [Video](https://youtu.be/_QloC8gVqDA).
3. Leveraging Episodic Memory to Improve World Models for Reinforcement Learning. Julian Coda-Forno, Changmin Yu, Qinghai Guo, Zafeirios Fountas, Neil Burgess. [Paper](papers/paper_3.pdf). [Video](https://youtu.be/Vd3SqFjLcT4).
4. Differentiable Neural Computers with Memory Demon. Ari Azarafrooz. [Paper](papers/paper_4.pdf). [Video](https://youtu.be/TplyJMKrMr4).
5. A Universal Abstraction for Hierarchical Hopfield Networks. Benjamin Hoover, Duen Horng Chau, Hendrik Strobelt, Dmitry Krotov. [Poster](posters/poster_5.pdf). [Video](https://www.youtube.com/watch?v=x_jJed5KjP8).
6. Interpolating Compressed Parameter Subspaces. Siddhartha Datta, Nigel Shadbolt. [Poster](unavailable). [Video](https://www.youtube.com/watch?v=J8L69slXjl4).
7. Associative memory via covariance-learning predictive coding networks. Mufeng Tang, Tommaso Salvatori, Yuhang Song, Beren Gray Millidge, Thomas Lukasiewicz, Rafal Bogacz. [Paper](papers/paper_7.pdf). [Video](https://youtu.be/Trn_1Q6qZdE).
8. Self-recovery of memory via generative replay. Zhenglong Zhou, Geshi Yeung, Anna C Schapiro. [Paper](papers/paper_9.pdf). [Video](https://www.youtube.com/watch?v=vx1raAyDgMY).
9. The Emergence of Abstract and Episodic Neurons in Episodic Meta-RL. Badr AlKhamissi, Muhammad ElNokrashy, Michael Spranger. [Paper](papers/paper_11.pdf). [Video](unavailable).
10. Multiple Modes for Continual Learning. Siddhartha Datta, Nigel Shadbolt. [Poster](unavailable). [Video](https://www.youtube.com/watch?v=rtH2EZeNcaw).
11. The Opportunistic PFC: Downstream Modulation of a Hippocampus-inspired Network is Optimal for Contextual Memory Recall. Hugo Chateau-Laurent, Frederic Alexandre. [Paper](papers/paper_14.pdf). [Video](https://recorder-v3.slideslive.com/?share=77434&s=5dd2ab3a-d730-45eb-a887-fd3d2c5639f1).
12. Recall-gated plasticity as a principle of systems memory consolidation. Jack Lindsey, Ashok Litwin-Kumar. [Poster](unavailable). [Video](unavailable).
13. Learning to Reason and Memorize with Self-Questioning. Jack Lanchantin, Shubham Toshniwal, Jason E Weston, Arthur Szlam, Sainbayar Sukhbaatar. [Paper](papers/paper_16.pdf). [Poster](posters/poster_16.pdf). [Video](https://recorder-v3.slideslive.com/#/share?share=78356&s=b216b880-3496-464c-a5d4-0cda4830c677).
14. Informing generative replay for continual learning with long-term memory formation in the fruit fly. Brian S Robinson, Justin Joyce, Raphael Norman-Tenazas, Gautam K Vallabha, Erik Christopher Johnson. [Paper](papers/paper_17.pdf). [Video](https://youtu.be/grJxdWNi10k).
15. Characterizing Verbatim Short-Term Memory in Neural Language Models. Kristijan Armeni, Christopher Honey, Tal Linzen. [Poster](unavailable). [Video](https://youtu.be/MWhsm4rMSxc).
16. Memory in humans and deep language models: Linking hypotheses for model augmentation. Omri Raccah, Phoebe Chen, Theodore L. Willke, David Poeppel, Vy A. Vo. [Paper](papers/paper_20.pdf). [Video](https://vimeo.com/manage/videos/771770003/privacy).
17. Transformers generalize differently from information stored in context vs in weights. Stephanie C.Y. Chan, Ishita Dasgupta, Junkyung Kim, Dharshan Kumaran, Andrew Kyle Lampinen, Felix Hill. [Paper](papers/paper_21.pdf). [Video](https://www.youtube.com/watch?v=Cqdyobq18Tk).
18. Mixed-Memory RNNs for Learning Long-term Dependencies in Irregularly-sampled Time Series. Mathias Lechner, Ramin Hasani. [Paper](papers/paper_23.pdf). [Video](https://youtu.be/E8hHioZM5-M).
19. Neural Network Online Training with Sensitivity to Multiscale Temporal Structure. Matt Jones, Tyler R. Scott, Gamaleldin Fathy Elsayed, Mengye Ren, Katherine Hermann, David Mayo, Michael Curtis Mozer. [Poster](unavailable). [Video](https://drive.google.com/file/d/1rERjhNuvvBBPCSF8bpWvUGJdxQOhAmiz/view?usp=drive_web).
20. Learning at Multiple Timescales. Matt Jones. [Paper](papers/paper_25.pdf). [Video](https://drive.google.com/file/d/1QDlePHw-TuE0wmVI9kbC_iO3CERr9WFk/view?usp=drive_web).
21. Toward Semantic History Compression for Reinforcement Learning. Fabian Paischer, Thomas Adler, Andreas Radler, Markus Hofmarcher, Sepp Hochreiter. [Paper](papers/paper_28.pdf). [Video](https://youtu.be/TIgZT4_2oOg).
22. CL-LSG: Continual Learning via Learnable Sparse Growth. Li Yang, Sen Lin, Junshan Zhang, Deliang Fan. [Paper](papers/paper_31.pdf). [Video](https://www.youtube.com/watch?v=i85GwHoU0aM).
23. Cache-Memory Gated Graph Neural Networks. Guixiang Ma, Vy A. Vo, Theodore L. Willke, Nesreen K. Ahmed. [Paper](papers/paper_32.pdf). [Video](unavailable).
24. Exploring The Precision of Real Intelligence Systems at Synapse Resolution. Mohammad Samavat, Thomas M Bartol, Kristen Harris, Terrence Sejnowski. [Paper](papers/paper_33.pdf). [Video](unavailable).
25. Low Resource Retrieval Augmented Adaptive Neural Machine Translation. Vivek Harsha Vardhan Lakkamaneni, Swair Shah, Anurag Beniwal, Narayanan Sadagopan. [Paper](papers/paper_34.pdf). [Video](https://drive.google.com/file/d/1GymE6_RvNk5SVPc1aXMOuczGNaPThbC2/view).
26. Neural networks learn an environment's geometry in latent space by performing predictive coding on visual scenes. James Gornet, Matt Thomson. [Paper](papers/paper_35.pdf). [Video](unavailable).
27. Transformer needs NMDA receptor nonlinearity for long-term memory. Dong-Kyum Kim, Jea Kwon, Meeyoung Cha, C. Justin Lee. [Poster](unavailable). [Video](https://youtu.be/PQA_HuXTfes).
28. Training language models for deeper understanding improves brain alignment. Khai Loong Aw, Mariya Toneva. [Poster](posters/poster_37.pdf). [Video](https://youtu.be/rEVvJb1odoo).
29. Using Hippocampal Replay to Consolidate Experiences in Memory-Augmented Reinforcement Learning. Chong Min John Tan, Mehul Motani. [Paper](papers/paper_38.pdf). [Video](https://www.youtube.com/watch?v=lm5ozEzoolE).
30. Evidence accumulation in deep RL agents powered by a cognitive model. James Mochizuki-Freeman, Sahaj Singh Maini, Zoran Tiganj. [Paper](papers/paper_39.pdf). [Poster](posters/poster_39.pdf). [Video](https://www.youtube.com/watch?v=RkbAsCRpsP0).
31. General-Purpose In-Context Learning by Meta-Learning Transformers. Louis Kirsch, James Harrison, Jascha Sohl-Dickstein, Luke Metz. [Poster](unavailable). [Video](https://youtu.be/k02rygHSlrA).
32. Experiences from the MediaEval Predicting Media Memorability Task. Alba Garcia Seco de Herrera, Mihai Gabriel Constantin, Claire-Helene Demarty, Camilo Luciano Fosco, Sebastian Halder, Graham Healy, Bogdan Ionescu, Ana Matran-Fernandez, Alan F. Smeaton, Mushfika Sultana. [Paper](papers/paper_41.pdf). [Video](https://youtu.be/LQyWnpQho6o).
33. Constructing compressed number lines of latent variables using a cognitive model of memory and deep neural networks. Sahaj Singh Maini, James Mochizuki-Freeman, Chirag Shankar Indi, Brandon G Jacques, Per B Sederberg, Marc Howard, Zoran Tiganj. [Paper](papers/paper_42.pdf). [Video](https://youtu.be/ZGJDHycWEBQ).
34. Learning to Control Rapidly Changing Synaptic Connections: An Alternative Type of Memory in Sequence Processing Artificial Neural Networks. Kazuki Irie, JÃ¼rgen Schmidhuber. [Paper](papers/paper_43.pdf). [Video](https://drive.google.com/file/d/1fguRNEZ0VvN0o-Ozb1ucPofdC5p48eot/view?usp=sharing).
