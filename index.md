MemARI is a [NeurIPS 2022](https://neurips.cc/Conferences/2022) workshop. Contact us via our Google Group (<memari-workshop@googlegroups.com> or <https://groups.google.com/g/memari-workshop>).

![MemARI logo](/img/logo.jpg){:height="50%" width="50%"}


## About

One of the key challenges for AI is to understand, predict, and model data over time. Pretrained networks should be able to temporally generalize, or adapt to shifts in data distributions that occur over time. Our current state-of-the-art (SOTA) still struggles to model and understand data over long temporal durations -- for example, SOTA models are limited to processing several seconds of video, and powerful transformer models are still fundamentally limited by their attention spans. On the other hand, humans and other biological systems are able to flexibly store and update information in memory to comprehend and manipulate multimodal streams of input. Cognitive neuroscientists propose that they do so via the interaction of multiple memory systems with different neural mechanisms. What types of memory systems and mechanisms already exist in our current AI models? First, there are extensions of the classic proposal that memories are formed via synaptic plasticity mechanisms – information can be stored in the static weights of a pre-trained network, or in fast weights that more closely resemble short-term plasticity mechanisms. Then there are persistent memory states, such as those in LSTMs or in external differentiable memory banks, which store information as neural activations that can change over time. Finally, there are models augmented with static databases of knowledge, akin to a high-precision long-term memory or semantic memory in humans. When is it useful to store information in each one of these mechanisms, and how should models retrieve from them or modify the information therein? How should we design models that may combine multiple memory mechanisms to address a problem? Furthermore, do the shortcomings of current models require some novel memory systems that retain information over different timescales, or with different capacity or precision? Finally, what can we learn from memory processes in biological systems that may advance our models in AI? We aim to explore how a deeper understanding of memory mechanisms can improve task performance in many different application domains, such as lifelong / continual learning, reinforcement learning, computer vision, and natural language processing.


## Important dates

| Event | Date
|:------ |:------
| Paper submission deadline | September 29nd, 2022 23:59 Anywhere on Earth
| Final decisions | October 14th, 2022 17:00 Pacific time
| Camera ready deadline | TBD
| Workshop date | December 2nd, 2022 in-person @ New Orleans


## Schedule

| Time | Location | Event | 
|:------ |:------ |:-----
| TBD | TBD | TBD


{% include people.html name="speakers" %}


{% include people.html name="organizers" %}


## Call for papers

We invite submissions to the NeurIPS 2022 workshop on **Memory in Artificial and Real Intelligence (MemARI)**. One of the key challenges for AI systems is to understand, predict, and model data over time. Pretrained networks should be able to temporally generalize, or adapt to shifts in data distributions that occur over time. Our current state-of-the-art (SOTA) still struggles to model and understand data over long temporal durations – for example, SOTA models are limited to processing several seconds of video, and powerful transformer models are still fundamentally limited by their attention spans. By contrast, humans and other biological systems are able to flexibly store and update information in memory to comprehend and manipulate streams of input.

How should memory mechanisms be designed in deep learning, and what can this field learn from biological memory systems? MemARI aims to facilitate progress on these topics by bringing together researchers from machine learning, neuroscience, reinforcement learning, computer vision, natural language processing and other adjacent fields. We invite submissions presenting new and original research on topics including but not limited to the following:
1. Computational models of biological memory
2. Role of different biological memory systems in cognitive tasks, with implications for AI algorithms/architectures
3. Biologically-inspired architectures to improve memory/temporal generalization
4. New approaches to improving memory in artificial systems
5. Domain-specific uses of memory mechanisms (e.g., lifelong learning, NLP, RL)
6. Empirical and theoretical analyses of limitations in current artificial systems
7. Datasets and tasks to evaluate memory mechanisms of artificial networks

### Submission instructions
* Submission Portal: [MemARI OpenReview](https://openreview.net/group?id=NeurIPS.cc/2022/Workshop/MemARI) (currently accepting submissions)
* All submissions must be in PDF format.
* Submissions are limited to four content pages, including all figures and tables; additional pages containing supplemental information & references are allowed. Reviewers should be able to judge your work without looking at the supplemental information.
* Please use the NeurIPS 2022 LaTeX style file. Style or page limit violations (e.g., by decreasing margins or font sizes) may lead to automatic rejection
* All submissions should be anonymous.
* Per NeurIPS guidelines, previously published work is not acceptable for submission.

### Reviewing process & Acceptance
* The review process is double-blind.
* Accepted papers will be presented during a poster session, with spotlight oral presentations for exceptional submissions. (with accommodation for virtual attendees)
* Accepted papers will be made publicly available as non-archival reports, allowing future submissions to archival conferences or journals.


Top image: [Mississippi River](<https://commons.wikimedia.org/wiki/File:Mississippi_River_(4117534034)_(cropped).jpg>), [CC BY-SA 3.0](https://creativecommons.org/licenses/by-sa/3.0), [Greg Willis](https://greg-willis.com), 2008.
